{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea1afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b489bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aai\\AppData\\Local\\Temp\\ipykernel_45912\\3831695973.py:4: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(lut_path, names=headers.split(\",\"), header=None)\n"
     ]
    }
   ],
   "source": [
    "headers = \"Cm,Ch,Bm,Bh,T,X,Y,Z,sR,sG,sB\"\n",
    "lut_path = r\"D:\\Github\\PhD Code\\Synthetic Data\\monte_carlo\\lut_rgb_BaseLine.csv\"\n",
    "\n",
    "df = pd.read_csv(lut_path, names=headers.split(\",\"), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4c77e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cm</th>\n",
       "      <th>Ch</th>\n",
       "      <th>Bm</th>\n",
       "      <th>Bh</th>\n",
       "      <th>T</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>sR</th>\n",
       "      <th>sG</th>\n",
       "      <th>sB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>melanin_concentration(Cm)</td>\n",
       "      <td>blood_concentration(Ch)</td>\n",
       "      <td>melanin_blend(Bm)</td>\n",
       "      <td>BloodOxy</td>\n",
       "      <td>epidermis_thickness(T)</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Z</td>\n",
       "      <td>sR</td>\n",
       "      <td>sG</td>\n",
       "      <td>sB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.05</td>\n",
       "      <td>74.714</td>\n",
       "      <td>79.1013</td>\n",
       "      <td>73.3911</td>\n",
       "      <td>236.063</td>\n",
       "      <td>229.876</td>\n",
       "      <td>211.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.09</td>\n",
       "      <td>74.8639</td>\n",
       "      <td>79.1686</td>\n",
       "      <td>73.8758</td>\n",
       "      <td>236.238</td>\n",
       "      <td>229.878</td>\n",
       "      <td>212.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.17</td>\n",
       "      <td>75.0629</td>\n",
       "      <td>79.3771</td>\n",
       "      <td>74.2289</td>\n",
       "      <td>236.422</td>\n",
       "      <td>230.151</td>\n",
       "      <td>212.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.6183</td>\n",
       "      <td>79.0106</td>\n",
       "      <td>73.1547</td>\n",
       "      <td>235.998</td>\n",
       "      <td>229.764</td>\n",
       "      <td>211.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839996</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.6121</td>\n",
       "      <td>1.5696</td>\n",
       "      <td>1.20872</td>\n",
       "      <td>40.91</td>\n",
       "      <td>31.841</td>\n",
       "      <td>26.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839997</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.43685</td>\n",
       "      <td>1.45939</td>\n",
       "      <td>1.237</td>\n",
       "      <td>36.375</td>\n",
       "      <td>31.36</td>\n",
       "      <td>26.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839998</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.47819</td>\n",
       "      <td>1.48677</td>\n",
       "      <td>1.23741</td>\n",
       "      <td>37.431</td>\n",
       "      <td>31.514</td>\n",
       "      <td>26.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839999</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952857</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.22331</td>\n",
       "      <td>1.86828</td>\n",
       "      <td>1.28201</td>\n",
       "      <td>54.037</td>\n",
       "      <td>31.454</td>\n",
       "      <td>27.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840000</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.27455</td>\n",
       "      <td>3.2389</td>\n",
       "      <td>2.43232</td>\n",
       "      <td>78.211</td>\n",
       "      <td>39.065</td>\n",
       "      <td>40.279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840001 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Cm                       Ch                 Bm  \\\n",
       "0       melanin_concentration(Cm)  blood_concentration(Ch)  melanin_blend(Bm)   \n",
       "1                           0.001                    0.001                  0   \n",
       "2                           0.001                    0.001                  0   \n",
       "3                           0.001                    0.001                  0   \n",
       "4                           0.001                    0.001                  0   \n",
       "...                           ...                      ...                ...   \n",
       "839996                        0.5                     0.32                1.0   \n",
       "839997                        0.5                     0.32                1.0   \n",
       "839998                        0.5                     0.32                1.0   \n",
       "839999                        0.5                     0.32                1.0   \n",
       "840000                        0.5                     0.32                1.0   \n",
       "\n",
       "              Bh                       T        X        Y        Z       sR  \\\n",
       "0       BloodOxy  epidermis_thickness(T)        X        Y        Z       sR   \n",
       "1       0.627143                    0.05   74.714  79.1013  73.3911  236.063   \n",
       "2       0.627143                    0.09  74.8639  79.1686  73.8758  236.238   \n",
       "3       0.627143                    0.17  75.0629  79.3771  74.2289  236.422   \n",
       "4       0.627143                    0.01  74.6183  79.0106  73.1547  235.998   \n",
       "...          ...                     ...      ...      ...      ...      ...   \n",
       "839996      0.98                    0.13   1.6121   1.5696  1.20872    40.91   \n",
       "839997      0.98                    0.25  1.43685  1.45939    1.237   36.375   \n",
       "839998      0.98                    0.21  1.47819  1.48677  1.23741   37.431   \n",
       "839999  0.952857                    0.05  2.22331  1.86828  1.28201   54.037   \n",
       "840000      0.98                    0.01  4.27455   3.2389  2.43232   78.211   \n",
       "\n",
       "             sG       sB  \n",
       "0            sG       sB  \n",
       "1       229.876  211.659  \n",
       "2       229.878  212.384  \n",
       "3       230.151  212.871  \n",
       "4       229.764  211.319  \n",
       "...         ...      ...  \n",
       "839996   31.841   26.229  \n",
       "839997    31.36   26.903  \n",
       "839998   31.514   26.859  \n",
       "839999   31.454   27.028  \n",
       "840000   39.065   40.279  \n",
       "\n",
       "[840001 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20f50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aai\\AppData\\Local\\Temp\\ipykernel_45912\\3995564710.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cm     Ch Bm        Bh     T        X        Y        Z       sR  \\\n",
      "1  0.001  0.001  0  0.627143  0.05   74.714  79.1013  73.3911  236.063   \n",
      "2  0.001  0.001  0  0.627143  0.09  74.8639  79.1686  73.8758  236.238   \n",
      "3  0.001  0.001  0  0.627143  0.17  75.0629  79.3771  74.2289  236.422   \n",
      "4  0.001  0.001  0  0.627143  0.01  74.6183  79.0106  73.1547  235.998   \n",
      "5  0.001  0.001  0  0.627143  0.13  75.0411  79.2762  74.4091  236.415   \n",
      "\n",
      "        sG       sB  \n",
      "1  229.876  211.659  \n",
      "2  229.878  212.384  \n",
      "3  230.151  212.871  \n",
      "4  229.764  211.319  \n",
      "5  229.945  213.169  \n",
      "840000\n",
      "      Cm     Ch   Bm        Bh     T        X        Y        Z     sR     sG  \\\n",
      "1  0.001  0.001  0.0  0.627143  0.05  74.7140  79.1013  73.3911  236.0  230.0   \n",
      "2  0.001  0.001  0.0  0.627143  0.09  74.8639  79.1686  73.8758  236.0  230.0   \n",
      "3  0.001  0.001  0.0  0.627143  0.17  75.0629  79.3771  74.2289  236.0  230.0   \n",
      "4  0.001  0.001  0.0  0.627143  0.01  74.6183  79.0106  73.1547  236.0  230.0   \n",
      "5  0.001  0.001  0.0  0.627143  0.13  75.0411  79.2762  74.4091  236.0  230.0   \n",
      "\n",
      "      sB  \n",
      "1  212.0  \n",
      "2  212.0  \n",
      "3  213.0  \n",
      "4  211.0  \n",
      "5  213.0  \n",
      "length of df 958003\n",
      "bef norm x_train[0] [159.612 120.733 127.799]\n",
      "aft norm x_train[0] [0.6259294  0.47346276 0.50117254]\n",
      "length of x_train 766401\n",
      "length of x_test 191600\n",
      "length of y_train 766401\n",
      "length of y_test 191600\n",
      "length of df 958003\n",
      "Cm = [np.float64(0.001), np.float64(0.00239541), np.float64(0.00439078), np.float64(0.00698613), np.float64(0.0101815), np.float64(0.0139767), np.float64(0.018372), np.float64(0.0233672), np.float64(0.0289625), np.float64(0.0351576), np.float64(0.0419528), np.float64(0.0493479), np.float64(0.057343), np.float64(0.0659381), np.float64(0.0751331), np.float64(0.0849281), np.float64(0.0953231), np.float64(0.106318), np.float64(0.117913), np.float64(0.130108), np.float64(0.142903), np.float64(0.156298), np.float64(0.170292), np.float64(0.184887), np.float64(0.200082), np.float64(0.215877), np.float64(0.232271), np.float64(0.249266), np.float64(0.266861), np.float64(0.285055), np.float64(0.30385), np.float64(0.323245), np.float64(0.343239), np.float64(0.363834), np.float64(0.385028), np.float64(0.406822), np.float64(0.429217), np.float64(0.452211), np.float64(0.475806), np.float64(0.5)]\n",
      "Ch = [np.float64(0.001), np.float64(0.0020536), np.float64(0.00348225), np.float64(0.00528595), np.float64(0.00746469), np.float64(0.0100185), np.float64(0.0129473), np.float64(0.0162512), np.float64(0.0199301), np.float64(0.0239841), np.float64(0.0284131), np.float64(0.0332172), np.float64(0.0383963), np.float64(0.0439505), np.float64(0.0498797), np.float64(0.0561839), np.float64(0.0628632), np.float64(0.0699176), np.float64(0.077347), np.float64(0.0851514), np.float64(0.0933309), np.float64(0.101885), np.float64(0.110815), np.float64(0.12012), np.float64(0.129799), np.float64(0.139854), np.float64(0.150284), np.float64(0.161089), np.float64(0.172268), np.float64(0.183823), np.float64(0.195753), np.float64(0.208058), np.float64(0.220738), np.float64(0.233793), np.float64(0.247224), np.float64(0.261029), np.float64(0.275209), np.float64(0.289764), np.float64(0.304695), np.float64(0.32)]\n",
      "Bm = [np.float64(0.0), np.float64(0.0625), np.float64(0.25), np.float64(0.5625), np.float64(1.0)]\n",
      "Bh = [np.float64(0.6), np.float64(0.627143), np.float64(0.654286), np.float64(0.681429), np.float64(0.708571), np.float64(0.735714), np.float64(0.762857), np.float64(0.79), np.float64(0.817143), np.float64(0.844286), np.float64(0.871429), np.float64(0.898571), np.float64(0.925714), np.float64(0.952857), np.float64(0.98)]\n",
      "T = [np.float64(0.01), np.float64(0.05), np.float64(0.09), np.float64(0.13), np.float64(0.17), np.float64(0.21), np.float64(0.25)]\n",
      "upper bounds = [np.float64(0.5), np.float64(0.32), np.float64(1.0), np.float64(0.98), np.float64(0.25)]\n",
      "lower bounds = [np.float64(0.001), np.float64(0.001), np.float64(0.0), np.float64(0.6), np.float64(0.01)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aai\\AppData\\Local\\Temp\\ipykernel_45912\\3995564710.py:106: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['sR', 'sG', 'sB']] = df[['sR', 'sG', 'sB']].applymap(np.round)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of repeated RGB values 930979\n"
     ]
    }
   ],
   "source": [
    "upper_bounds = [0.5, 0.32, 1.0, 0.98, 0.25]\n",
    "lower_bounds = [0.001, 0.001, 0.0, 0.6, 0.01]\n",
    "\n",
    "# Pair up the corresponding bounds and calculate their average\n",
    "averages = [(u + l) / 2 for u, l in zip(upper_bounds, lower_bounds)]\n",
    "avg_Cm, avg_Ch, avg_Bm, avg_Bh, avg_T = averages\n",
    "\n",
    "\n",
    "#remove row 0\n",
    "df = df.iloc[1:]\n",
    "print(df.head())\n",
    "\n",
    "#print length of df\n",
    "print(len(df))\n",
    "# convert all columns to float\n",
    "for column in df.columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "#convert sR, sG, sB to int\n",
    "rounded_df = df.round({'sR': 0, 'sG': 0, 'sB': 0})\n",
    "# Step 1: Find duplicate RGB values\n",
    "duplicates = rounded_df[rounded_df.duplicated(subset=['sR', 'sG', 'sB'], keep=False)].copy() # added .copy()\n",
    "#print all duplicates\n",
    "print(duplicates.head())\n",
    "\n",
    "# Step 2: Calculate the 'likelihood' score for each row\n",
    "duplicates['likelihood'] = (abs(duplicates['Cm'] - avg_Cm) +\n",
    "                            abs(duplicates['Ch'] - avg_Ch) +\n",
    "                            abs(duplicates['Bm'] - avg_Bm) +\n",
    "                            abs(duplicates['Bh'] - avg_Bh) +\n",
    "                            abs(duplicates['T'] - avg_T))\n",
    "\n",
    "# Step 3: Sort by RGB values and likelihood, keeping the row with the lowest likelihood for each RGB group\n",
    "most_likely_duplicates = duplicates.sort_values(['sR', 'sG', 'sB', 'likelihood']).drop_duplicates(subset=['sR', 'sG', 'sB'])\n",
    "\n",
    "# Now, most_likely_duplicates should contain your desired rows\n",
    "\n",
    "# First, remove all duplicates from the original dataframe\n",
    "df_no_duplicates = df.drop_duplicates(subset=['sR', 'sG', 'sB'], keep=False)\n",
    "\n",
    "# Concatenate df_no_duplicates with most_likely_duplicates to get the final dataframe\n",
    "df = pd.concat([df_no_duplicates, most_likely_duplicates])\n",
    "\n",
    "# If you want to sort it based on index\n",
    "df.sort_index(inplace=True)\n",
    "df.head()\n",
    "#remove duplicates\n",
    "\n",
    "x = df[['sR', 'sG', 'sB']].to_numpy(dtype='float32')\n",
    "y = df[['Cm', 'Ch', 'Bm', 'Bh', 'T']].to_numpy(dtype='float32')\n",
    "#create new csv with headers\n",
    "# df.to_csv(r'LUTs\\large_no_duplicates.csv', index=False, header=True)\n",
    "\n",
    "\n",
    "#train nn on x,y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "#remove any header values\n",
    "x_train = x_train[1:]\n",
    "x_test = x_test[1:]\n",
    "y_train = y_train[1:]\n",
    "y_test = y_test[1:]\n",
    "\n",
    "#numpy arrays\n",
    "x_train = np.asarray(x_train).reshape(-1,3).astype('float32')\n",
    "x_test = np.asarray(x_test).reshape(-1,3).astype('float32')\n",
    "print(f\"length of df {len(df)}\")\n",
    "print(f\"bef norm x_train[0] {x_train[0]}\")\n",
    "\n",
    "#normalize\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "print(f\"aft norm x_train[0] {x_train[0]}\")\n",
    "\n",
    "print(f\"length of x_train {len(x_train)}\")\n",
    "print(f\"length of x_test {len(x_test)}\")\n",
    "print(f\"length of y_train {len(y_train)}\")\n",
    "print(f\"length of y_test {len(y_test)}\")\n",
    "df.head()\n",
    "print(f\"length of df {len(df)}\")\n",
    "#print random 3 rows\n",
    "#print unique values of Cm,Ch,Bm,Bh,T\n",
    "# print(f\"unique Cm {df['Cm'].unique()}\")\n",
    "# print(f\"unique Ch {df['Ch'].unique()}\")\n",
    "# print(f\"unique Bm {df['Bm'].unique()}\")\n",
    "# print(f\"unique Bh {df['Bh'].unique()}\")\n",
    "# print(f\"unique T {df['T'].unique()}\")\n",
    "#as sorted lists\n",
    "C_m = sorted(df['Cm'].unique())\n",
    "C_h = sorted(df['Ch'].unique())\n",
    "B_m = sorted(df['Bm'].unique())\n",
    "B_h = sorted(df['Bh'].unique())\n",
    "T = sorted(df['T'].unique())\n",
    "print(f\"Cm = {C_m}\")\n",
    "print(f\"Ch = {C_h}\")\n",
    "print(f\"Bm = {B_m}\")\n",
    "print(f\"Bh = {B_h}\")\n",
    "print(f\"T = {T}\")\n",
    "#min max for each\n",
    "min_vals = [min(C_m), min(C_h), min(B_m), min(B_h), min(T)]\n",
    "max_vals = [max(C_m), max(C_h), max(B_m), max(B_h), max(T)]\n",
    "print(f\"upper bounds = {max_vals}\")\n",
    "print(f\"lower bounds = {min_vals}\")\n",
    "#integer arrays for sR,sG,sB 0 to 255\n",
    "# Assuming df is your DataFrame and it has columns 'sR', 'sG', 'sB'\n",
    "df[['sR', 'sG', 'sB']] = df[['sR', 'sG', 'sB']].astype(float)\n",
    "df[['sR', 'sG', 'sB']] = df[['sR', 'sG', 'sB']].applymap(np.round)\n",
    "# Add a 'count' column that counts the number of identical RGB values\n",
    "df['count'] = df.groupby(['sR', 'sG', 'sB'])['sR'].transform('count')\n",
    "print(f\"number of repeated RGB values {len(df[df['count'] > 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b922472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Reproducibility (np.random.seed(7) equivalent)\n",
    "# -----------------------------\n",
    "np.random.seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed_all(7)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameters (from your code)\n",
    "# -----------------------------\n",
    "BATCH_SIZE = 4096 * 16\n",
    "NUM_NEURONS = 75\n",
    "NUM_LAYERS = 2\n",
    "NUM_EPOCHS = 200\n",
    "LR = 1e-4\n",
    "MLR = 1e-6  # unused in your compile; keeping for parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848fb777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train_loader...\n",
      "Batch contains 6 tensors\n",
      "  Item 0: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "  Item 1: shape = torch.Size([65536, 5]), type = <class 'torch.Tensor'>\n",
      "  Item 2: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "  Item 3: shape = torch.Size([65536, 5]), type = <class 'torch.Tensor'>\n",
      "  Item 4: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "  Item 5: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "\n",
      "Checking val_loader...\n",
      "Batch contains 6 tensors\n",
      "  Item 0: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "  Item 1: shape = torch.Size([65536, 5]), type = <class 'torch.Tensor'>\n",
      "  Item 2: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "  Item 3: shape = torch.Size([65536, 5]), type = <class 'torch.Tensor'>\n",
      "  Item 4: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n",
      "  Item 5: shape = torch.Size([65536, 3]), type = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AEDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.from_numpy(x).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_i = self.x[idx]   # [3]\n",
    "        y_i = self.y[idx]   # [5]\n",
    "        \n",
    "        enc_in = x_i\n",
    "        dec_in = y_i\n",
    "        end_in = x_i\n",
    "        \n",
    "        enc_true = y_i\n",
    "        dec_true = x_i\n",
    "        end_true = x_i\n",
    "        \n",
    "        return enc_in, dec_in, end_in, enc_true, dec_true, end_true\n",
    "\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = AEDataset(x_train, y_train)\n",
    "val_dataset = AEDataset(x_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# DEBUG: Let's see what the dataloader is actually giving us\n",
    "print(\"Checking train_loader...\")\n",
    "for batch in train_loader:\n",
    "    print(f\"Batch contains {len(batch)} tensors\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"  Item {i}: shape = {item.shape if hasattr(item, 'shape') else 'NO SHAPE'}, type = {type(item)}\")\n",
    "    break  # Just check first batch\n",
    "\n",
    "print(\"\\nChecking val_loader...\")\n",
    "for batch in val_loader:\n",
    "    print(f\"Batch contains {len(batch)} tensors\")\n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"  Item {i}: shape = {item.shape if hasattr(item, 'shape') else 'NO SHAPE'}, type = {type(item)}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f9fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def show_training_progress(encoder, decoder, x_batch, y_batch, device, epoch, save_dir):\n",
    "    \"\"\"\n",
    "    Shows RGB → Encoder → Latent → Decoder → RGB\n",
    "    Saves visualization to file and returns metrics\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        latent_predicted = encoder(x_batch[:3])\n",
    "        rgb_output = decoder(latent_predicted)\n",
    "    \n",
    "    # Convert to readable format\n",
    "    rgb_input = (x_batch[:3].cpu().numpy() * 255).astype(int)\n",
    "    latent_pred = latent_predicted.cpu().numpy()\n",
    "    latent_true = y_batch[:3].cpu().numpy()\n",
    "    rgb_recon = (rgb_output.cpu().numpy() * 255).astype(int)\n",
    "    \n",
    "    # Create plot\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "    fig.suptitle(f'Epoch {epoch} - Training Progress', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    params = ['Cm', 'Ch', 'Bm', 'Bh', 'T']\n",
    "    \n",
    "    for i in range(3):\n",
    "        # Input color\n",
    "        axes[i,0].imshow([[rgb_input[i]/255.0]])\n",
    "        axes[i,0].set_title(f'Input\\n{rgb_input[i]}')\n",
    "        axes[i,0].axis('off')\n",
    "        \n",
    "        # True parameters\n",
    "        axes[i,1].barh(params, latent_true[i], color='green', alpha=0.6)\n",
    "        axes[i,1].set_xlim(0,1)\n",
    "        axes[i,1].set_title('True Parameters')\n",
    "        \n",
    "        # Predicted parameters\n",
    "        axes[i,2].barh(params, latent_pred[i], color='orange', alpha=0.6)\n",
    "        axes[i,2].set_xlim(0,1)\n",
    "        axes[i,2].set_title('Encoder Output')\n",
    "        \n",
    "        # Reconstructed color\n",
    "        axes[i,3].imshow([[rgb_recon[i]/255.0]])\n",
    "        axes[i,3].set_title(f'Output\\n{rgb_recon[i]}')\n",
    "        axes[i,3].axis('off')\n",
    "        \n",
    "        # Error\n",
    "        error = np.abs(rgb_input[i] - rgb_recon[i])\n",
    "        axes[i,4].axis('off')\n",
    "        axes[i,4].text(0.1, 0.5, f'Error:\\n{error}\\n\\nAvg: {error.mean():.1f}',\n",
    "                      fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # SAVE to file\n",
    "    save_path = os.path.join(save_dir, f'epoch_{epoch:04d}.png')\n",
    "    plt.savefig(save_path, dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Return metrics for logging\n",
    "    metrics = []\n",
    "    for i in range(3):\n",
    "        error = np.abs(rgb_input[i] - rgb_recon[i])\n",
    "        metrics.append({\n",
    "            'sample': i,\n",
    "            'rgb_input': rgb_input[i].tolist(),\n",
    "            'rgb_output': rgb_recon[i].tolist(),\n",
    "            'mean_error': float(error.mean())\n",
    "        })\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f934a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# DEVICE\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL COMPONENTS\n",
    "# -----------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden_dim=NUM_NEURONS, num_layers=NUM_LAYERS, out_dim=5):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(in_dim if i == 0 else hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.out = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_dim=5, hidden_dim=NUM_NEURONS, num_layers=NUM_LAYERS, out_dim=3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.Linear(in_dim if i == 0 else hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.out = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, encoder_in, decoder_in, end_to_end_in):\n",
    "        enc_out = self.encoder(encoder_in)\n",
    "        dec_out = self.decoder(decoder_in)\n",
    "        end_out = self.decoder(self.encoder(end_to_end_in))\n",
    "        return enc_out, dec_out, end_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Loss functions (same as before)\n",
    "# -----------------------------\n",
    "def albedo_loss(y_true, y_pred):\n",
    "    return torch.sum(torch.abs(y_pred - y_true), dim=-1)\n",
    "\n",
    "def parameter_loss(y_true, y_pred):\n",
    "    return torch.sqrt(torch.sum((y_pred - y_true) ** 2, dim=-1) + 1e-12)\n",
    "\n",
    "def end_to_end_loss(y_true, y_pred):\n",
    "    return torch.sum(torch.abs(y_pred - y_true), dim=-1)\n",
    "\n",
    "def reduce_loss(loss_per_sample, reduction=\"mean\"):\n",
    "    if reduction == \"mean\":\n",
    "        return loss_per_sample.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        return loss_per_sample.sum()\n",
    "    else:\n",
    "        raise ValueError(\"reduction must be 'mean' or 'sum'\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run folder creation (date/time)\n",
    "# -----------------------------\n",
    "def create_run_folder(base_dir=\"checkpoints\"):\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_dir = os.path.join(base_dir, now)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation loop (val)\n",
    "# -----------------------------\n",
    "def evaluate(model, dataloader, loss_weights=(0.3, 0.1, 0.6)):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss_sum = 0.0\n",
    "    loss1_sum = 0.0\n",
    "    loss2_sum = 0.0\n",
    "    loss3_sum = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            enc_in, dec_in, end_in, enc_true, dec_true, end_true = batch\n",
    "\n",
    "            enc_in   = enc_in.to(device)\n",
    "            dec_in   = dec_in.to(device)\n",
    "            end_in   = end_in.to(device)\n",
    "            enc_true = enc_true.to(device)\n",
    "            dec_true = dec_true.to(device)\n",
    "            end_true = end_true.to(device)\n",
    "\n",
    "            enc_pred, dec_pred, end_pred = model(enc_in, dec_in, end_in)\n",
    "\n",
    "            loss1 = reduce_loss(parameter_loss(enc_true, enc_pred), \"mean\")\n",
    "            loss2 = reduce_loss(albedo_loss(dec_true, dec_pred), \"mean\")\n",
    "            loss3 = reduce_loss(end_to_end_loss(end_true, end_pred), \"mean\")\n",
    "\n",
    "            total_loss = loss_weights[0]*loss1 + loss_weights[1]*loss2 + loss_weights[2]*loss3\n",
    "\n",
    "            total_loss_sum += total_loss.item()\n",
    "            loss1_sum += loss1.item()\n",
    "            loss2_sum += loss2.item()\n",
    "            loss3_sum += loss3.item()\n",
    "            n_batches += 1\n",
    "\n",
    "    if n_batches == 0:\n",
    "        return {\"total\": 0.0, \"loss1\": 0.0, \"loss2\": 0.0, \"loss3\": 0.0}\n",
    "\n",
    "    return {\n",
    "        \"total\": total_loss_sum / n_batches,\n",
    "        \"loss1\": loss1_sum / n_batches,\n",
    "        \"loss2\": loss2_sum / n_batches,\n",
    "        \"loss3\": loss3_sum / n_batches,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training loop (train + val)\n",
    "# -----------------------------\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=200,\n",
    "    loss_weights=(0.3, 0.1, 0.6),\n",
    "    base_ckpt_dir=\"checkpoints\",\n",
    "    checkpoint_period=200,\n",
    "    print_period=25,\n",
    "    save_json_each_epoch=True,\n",
    "):\n",
    "    run_dir = create_run_folder(base_ckpt_dir)\n",
    "    best_ckpt_path = os.path.join(run_dir, \"best.pt\")\n",
    "    last_ckpt_path = os.path.join(run_dir, \"last.pt\")\n",
    "    json_path = os.path.join(run_dir, \"history.json\")\n",
    "\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"Run folder:\", run_dir)\n",
    "\n",
    "    # CREATE VISUALIZATION FOLDER\n",
    "    viz_dir = os.path.join(run_dir, \"visualizations\")\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    # CREATE LOG FILE\n",
    "    log_file_path = os.path.join(viz_dir, \"training_log.txt\")\n",
    "    with open(log_file_path, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"AUTOENCODER TRAINING LOG\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Device: {device}\\n\")\n",
    "        f.write(f\"Number of Epochs: {num_epochs}\\n\")\n",
    "        f.write(f\"Batch Size: {train_loader.batch_size}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "    print(\"Using device:\", device)\n",
    "    print(\"Run folder:\", run_dir)\n",
    "    print(\"Visualizations folder:\", viz_dir)\n",
    "    print(\"Training log:\", log_file_path)\n",
    "\n",
    "    best_train_loss = float(\"inf\")\n",
    "\n",
    "    history = {\n",
    "        \"config\": {\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"loss_weights\": loss_weights,\n",
    "            \"optimizer\": optimizer.__class__.__name__,\n",
    "            \"scheduler\": scheduler.__class__.__name__,\n",
    "            \"device\": str(device),\n",
    "        },\n",
    "        \"epochs\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        total_loss_sum = 0.0\n",
    "        loss1_sum = 0.0\n",
    "        loss2_sum = 0.0\n",
    "        loss3_sum = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            enc_in, dec_in, end_in, enc_true, dec_true, end_true = batch\n",
    "\n",
    "            enc_in   = enc_in.to(device)\n",
    "            dec_in   = dec_in.to(device)\n",
    "            end_in   = end_in.to(device)\n",
    "            enc_true = enc_true.to(device)\n",
    "            dec_true = dec_true.to(device)\n",
    "            end_true = end_true.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enc_pred, dec_pred, end_pred = model(enc_in, dec_in, end_in)\n",
    "\n",
    "            loss1 = reduce_loss(parameter_loss(enc_true, enc_pred), \"mean\")\n",
    "            loss2 = reduce_loss(albedo_loss(dec_true, dec_pred), \"mean\")\n",
    "            loss3 = reduce_loss(end_to_end_loss(end_true, end_pred), \"mean\")\n",
    "\n",
    "            total_loss = loss_weights[0]*loss1 + loss_weights[1]*loss2 + loss_weights[2]*loss3\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss_sum += total_loss.item()\n",
    "            loss1_sum += loss1.item()\n",
    "            loss2_sum += loss2.item()\n",
    "            loss3_sum += loss3.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        train_stats = {\n",
    "            \"total\": total_loss_sum / max(n_batches, 1),\n",
    "            \"loss1\": loss1_sum / max(n_batches, 1),\n",
    "            \"loss2\": loss2_sum / max(n_batches, 1),\n",
    "            \"loss3\": loss3_sum / max(n_batches, 1),\n",
    "        }\n",
    "\n",
    "        val_stats = evaluate(model, val_loader, loss_weights=loss_weights)\n",
    "\n",
    "        # Keras ReduceLROnPlateau monitors train loss in your code\n",
    "        scheduler.step(train_stats[\"total\"])\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Logging record for this epoch\n",
    "        epoch_record = {\n",
    "            \"epoch\": epoch,\n",
    "            \"lr\": current_lr,\n",
    "            \"train\": train_stats,\n",
    "            \"val\": val_stats,\n",
    "        }\n",
    "        history[\"epochs\"].append(epoch_record)\n",
    "\n",
    "        # Save JSON file continuously (optional)\n",
    "        if save_json_each_epoch:\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(history, f, indent=6)\n",
    "\n",
    "       \n",
    "        # Print callback every N epochs\n",
    "        # Print callback every N epochs\n",
    "        if epoch % print_period == 0:\n",
    "            print(\n",
    "                f\"epoch: {epoch} | \"\n",
    "                f\"train_total={train_stats['total']:.6f} \"\n",
    "                f\"(L1={train_stats['loss2']:.6f}, L2={train_stats['loss1']:.6f}, end={train_stats['loss3']:.6f}) | \"\n",
    "                f\"val_total={val_stats['total']:.6f} \"\n",
    "                f\"(L1={val_stats['loss2']:.6f}, L2={val_stats['loss1']:.6f}, end={val_stats['loss3']:.6f}) | \"\n",
    "                f\"lr={current_lr:.2e}\"\n",
    "            )\n",
    "\n",
    "        # VISUALIZE EVERY EPOCH (not just print_period)\n",
    "        for val_batch in val_loader:\n",
    "            break\n",
    "        end_in, end_true = val_batch[2], val_batch[5]\n",
    "\n",
    "        vis_metrics = show_training_progress(\n",
    "            model.encoder, \n",
    "            model.decoder, \n",
    "            end_in.to(device), \n",
    "            end_true.to(device), \n",
    "            device, \n",
    "            epoch,\n",
    "            viz_dir\n",
    "        )\n",
    "\n",
    "        # LOG TO TEXT FILE EVERY EPOCH\n",
    "        with open(log_file_path, 'a') as f:\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"EPOCH {epoch}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\")\n",
    "            f.write(f\"Train Loss:  {train_stats['total']:.6f} \")\n",
    "            f.write(f\"(param={train_stats['loss1']:.6f}, albedo={train_stats['loss2']:.6f}, e2e={train_stats['loss3']:.6f})\\n\")\n",
    "            f.write(f\"Val Loss:    {val_stats['total']:.6f} \")\n",
    "            f.write(f\"(param={val_stats['loss1']:.6f}, albedo={val_stats['loss2']:.6f}, e2e={val_stats['loss3']:.6f})\\n\")\n",
    "            f.write(f\"LR:          {current_lr:.2e}\\n\")\n",
    "            f.write(f\"Viz Errors:  \")\n",
    "            for m in vis_metrics:\n",
    "                f.write(f\"Sample{m['sample']}={m['mean_error']:.2f} \")\n",
    "            f.write(f\"\\nImage saved: epoch_{epoch:04d}.png\\n\")\n",
    "\n",
    "\n",
    "        # Save BEST model (like ModelCheckpoint(save_best_only=True))\n",
    "        if train_stats[\"total\"] < best_train_loss:\n",
    "            best_train_loss = train_stats[\"total\"]\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"best_train_loss\": best_train_loss,\n",
    "                    \"history_path\": json_path,\n",
    "                },\n",
    "                best_ckpt_path,\n",
    "            )\n",
    "\n",
    "        # Save periodic checkpoint (every checkpoint_period epochs)\n",
    "        if (epoch + 1) % checkpoint_period == 0:\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"train_total_loss\": train_stats[\"total\"],\n",
    "                    \"val_total_loss\": val_stats[\"total\"],\n",
    "                    \"history_path\": json_path,\n",
    "                },\n",
    "                last_ckpt_path,\n",
    "            )\n",
    "\n",
    "    # final save JSON (ensures up-to-date)\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(history, f, indent=6)\n",
    "\n",
    "   # FINAL LOG ENTRY\n",
    "    with open(log_file_path, 'a') as f:\n",
    "        f.write(f\"\\n{'='*80}\\n\")\n",
    "        f.write(\"TRAINING COMPLETE\\n\")\n",
    "        f.write(f\"{'='*80}\\n\")\n",
    "        f.write(f\"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Best Training Loss: {best_train_loss:.6f}\\n\")\n",
    "        f.write(f\"Total Visualizations: {num_epochs}\\n\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(f\"All {num_epochs} visualizations saved in: {viz_dir}\")\n",
    "    print(f\"Training log: {log_file_path}\")\n",
    "\n",
    "    return history, run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2895275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Run folder: checkpoints\\2026-02-24_14-11-42\n",
      "Using device: cuda\n",
      "Run folder: checkpoints\\2026-02-24_14-11-42\n",
      "Visualizations folder: checkpoints\\2026-02-24_14-11-42\\visualizations\n",
      "Training log: checkpoints\\2026-02-24_14-11-42\\visualizations\\training_log.txt\n",
      "epoch: 0 | train_total=1.178348 (L1=1.272290, L2=0.963346, end=1.270191) | val_total=1.149902 (L1=1.240290, L2=0.941673, end=1.238951) | lr=1.00e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (3,) and arg 3 with shape (5,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR)\n\u001b[0;32m      7\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[0;32m      8\u001b[0m     optimizer,\n\u001b[0;32m      9\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     min_lr\u001b[38;5;241m=\u001b[39mMLR,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m history, run_dir \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_ckpt_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_json_each_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m best_checkpoint \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest checkpoint saved at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_checkpoint)\n",
      "Cell \u001b[1;32mIn[8], line 286\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, optimizer, scheduler, num_epochs, loss_weights, base_ckpt_dir, checkpoint_period, print_period, save_json_each_epoch)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    284\u001b[0m end_in, end_true \u001b[38;5;241m=\u001b[39m val_batch[\u001b[38;5;241m2\u001b[39m], val_batch[\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m--> 286\u001b[0m vis_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mshow_training_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_true\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mviz_dir\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# LOG TO TEXT FILE EVERY EPOCH\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m, in \u001b[0;36mshow_training_progress\u001b[1;34m(encoder, decoder, x_batch, y_batch, device, epoch, save_dir)\u001b[0m\n\u001b[0;32m     34\u001b[0m axes[i,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# True parameters\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbarh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_true\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m axes[i,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlim(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m axes[i,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\deep-albedo\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2834\u001b[0m, in \u001b[0;36mAxes.barh\u001b[1;34m(self, y, width, height, left, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2704\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2705\u001b[0m \u001b[38;5;124;03mMake a horizontal bar plot.\u001b[39;00m\n\u001b[0;32m   2706\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2831\u001b[0m \u001b[38;5;124;03m:doc:`/gallery/lines_bars_and_markers/horizontal_barchart_distribution`.\u001b[39;00m\n\u001b[0;32m   2832\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2834\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbar(x\u001b[38;5;241m=\u001b[39mleft, height\u001b[38;5;241m=\u001b[39mheight, width\u001b[38;5;241m=\u001b[39mwidth, bottom\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2835\u001b[0m                    align\u001b[38;5;241m=\u001b[39malign, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m patches\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\deep-albedo\\lib\\site-packages\\matplotlib\\__init__.py:1524\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[0;32m   1525\u001b[0m             ax,\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(cbook\u001b[38;5;241m.\u001b[39msanitize_sequence, args),\n\u001b[0;32m   1527\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: cbook\u001b[38;5;241m.\u001b[39msanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m   1529\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1531\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\deep-albedo\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2583\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2581\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2583\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2584\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2587\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\deep-albedo\\lib\\site-packages\\numpy\\lib\\_stride_tricks_impl.py:544\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    542\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 544\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m result \u001b[38;5;241m=\u001b[39m [array \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape\n\u001b[0;32m    547\u001b[0m           \u001b[38;5;28;01melse\u001b[39;00m _broadcast_to(array, shape, subok\u001b[38;5;241m=\u001b[39msubok, readonly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    548\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\Aai\\anaconda3\\envs\\deep-albedo\\lib\\site-packages\\numpy\\lib\\_stride_tricks_impl.py:419\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (3,) and arg 3 with shape (5,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x900 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_net = Encoder().to(device)\n",
    "decoder_net = Decoder().to(device)\n",
    "model = AutoEncoder(encoder_net, decoder_net).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.01,\n",
    "    patience=5,\n",
    "    threshold=1e-4,\n",
    "    cooldown=0,\n",
    "    min_lr=MLR,\n",
    ")\n",
    "\n",
    "history, run_dir = train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    loss_weights=(0.3, 0.1, 0.6),\n",
    "    base_ckpt_dir=\"checkpoints\",\n",
    "    checkpoint_period=200,\n",
    "    print_period=5,\n",
    "    save_json_each_epoch=True,\n",
    ")\n",
    "\n",
    "best_checkpoint = os.path.join(run_dir, \"best.pt\")\n",
    "print(\"Best checkpoint saved at:\", best_checkpoint)\n",
    "print(\"Run directory:\", run_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "\n",
    "# device setup (equivalent to tf.device('/device:GPU:0'))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Make sure encoder / decoder are already defined and moved to device:\n",
    "# encoder.to(device)\n",
    "# decoder.to(device)\n",
    "# encoder.eval()\n",
    "# decoder.eval()\n",
    "\n",
    "\n",
    "def encode(image, encoder):\n",
    "    \"\"\"\n",
    "    PyTorch version of TensorFlow encode()\n",
    "    Input: image (numpy array), encoder (torch.nn.Module)\n",
    "    Output: pred_maps (numpy), elapsed (float), (WIDTH, HEIGHT)\n",
    "    \"\"\"\n",
    "    print(f\"Image shape at start of encoder method: {image.shape}\")\n",
    "\n",
    "    # Handle 2D flattened input vs image input\n",
    "    if len(image.shape) == 2:\n",
    "        WIDTH = HEIGHT = int(math.sqrt(image.shape[0]))\n",
    "        # your code: reshape(-1,4) then later reshape(W*H,3)\n",
    "        # This implies the 4th channel was ignored later.\n",
    "        # We'll keep it identical:\n",
    "        image = np.asarray(image).reshape(-1, 4).astype(\"float32\")\n",
    "    else:\n",
    "        WIDTH = image.shape[0]\n",
    "        HEIGHT = image.shape[1]\n",
    "        image = np.asarray(image).astype(\"float32\")\n",
    "\n",
    "    # match your Keras reshape\n",
    "    image = image.reshape(WIDTH * HEIGHT, 3)\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Image shape before encoder inference: {image.shape}\")\n",
    "\n",
    "    # Convert to torch tensor and run model inference\n",
    "    x = torch.from_numpy(image).to(device)\n",
    "\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_maps = encoder(x)\n",
    "\n",
    "    # Convert back to numpy\n",
    "    pred_maps = pred_maps.detach().cpu().numpy()\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "\n",
    "    # reshape output to (WIDTH*HEIGHT, 5)\n",
    "    pred_maps = pred_maps.reshape(WIDTH * HEIGHT, 5)\n",
    "\n",
    "    return pred_maps, elapsed, (WIDTH, HEIGHT)\n",
    "\n",
    "\n",
    "def decode(encoded, decoder):\n",
    "    \"\"\"\n",
    "    PyTorch version of TensorFlow decode()\n",
    "    Input: encoded (numpy array), decoder (torch.nn.Module)\n",
    "    Output: recovered (numpy), elapsed (float), (WIDTH, HEIGHT)\n",
    "    \"\"\"\n",
    "    print(f\"Image shape going into encoder: {encoded.shape}\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Handle 2D flattened input vs (W,H,C) style input\n",
    "    if len(encoded.shape) == 2:\n",
    "        WIDTH = HEIGHT = int(math.sqrt(encoded.shape[0]))\n",
    "        encoded = np.asarray(encoded).reshape(-1, 5).astype(\"float32\")\n",
    "    else:\n",
    "        WIDTH = encoded.shape[0]\n",
    "        HEIGHT = encoded.shape[1]\n",
    "        encoded = np.asarray(encoded).astype(\"float32\")\n",
    "\n",
    "    print(f\"encoded shape going into decoder: {encoded.shape}\")\n",
    "\n",
    "    # Torch inference\n",
    "    x = torch.from_numpy(encoded).to(device)\n",
    "\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        recovered = decoder(x)\n",
    "\n",
    "    recovered = recovered.detach().cpu().numpy()\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "\n",
    "    # reshape output to RGB image\n",
    "    recovered = recovered.reshape(WIDTH, HEIGHT, 3)\n",
    "\n",
    "    return recovered, elapsed, (WIDTH, HEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05b49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9415afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67153604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc659287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363a649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ac264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fcaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-albedo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
